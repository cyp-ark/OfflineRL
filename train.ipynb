{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, yaml, wandb, pickle, optuna, gc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.utils.data import TensorDataset, DataLoader, Sampler\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('stru_AE.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_transition(data):\n",
    "    df = pd.read_parquet(data)\n",
    "    s_col = [x for x in df if x[:2]=='s:']\n",
    "    a_col = [x for x in df if x[:2]=='a:']\n",
    "    r_col = [x for x in df if x[:2]=='r:']\n",
    "    \n",
    "    dict = {}\n",
    "    dict['traj'] = {}\n",
    "\n",
    "    s,a,r,s2,t  = [],[],[],[],[]\n",
    "    \n",
    "    for traj in df.traj.unique():\n",
    "        df_traj = df[df['traj'] == traj]\n",
    "        dict['traj'][traj] = {'s':[],'a':[],'r':[]}\n",
    "        dict['traj'][traj]['s'] = df_traj[s_col].values.tolist()\n",
    "        dict['traj'][traj]['a'] = df_traj[a_col].values.tolist()\n",
    "        dict['traj'][traj]['r'] = df_traj[r_col].values.tolist()\n",
    "        \n",
    "        step_len = len(df_traj) - 1\n",
    "        for step in range(step_len):\n",
    "            s.append(dict['traj'][traj]['s'][step])\n",
    "            a.append(dict['traj'][traj]['a'][step])\n",
    "            r.append(dict['traj'][traj]['r'][step+1])\n",
    "            s2.append(dict['traj'][traj]['s'][step+1])\n",
    "            t.append(0)\n",
    "        s.append(dict['traj'][traj]['s'][step_len-1])\n",
    "        a.append(dict['traj'][traj]['a'][step_len-1])\n",
    "        r.append(dict['traj'][traj]['r'][step_len])\n",
    "        s2.append(dict['traj'][traj]['s'][step_len])\n",
    "        t.append(1)\n",
    "    \n",
    "    s  = torch.FloatTensor(np.float32(s))\n",
    "    a  = torch.LongTensor(np.int64(a))\n",
    "    r  = torch.FloatTensor(np.float32(r))\n",
    "    s2 = torch.FloatTensor(np.float32(s2))\n",
    "    t  = torch.FloatTensor(np.float32(t))\n",
    "    Dataset = TensorDataset(s, a, r, s2, t)\n",
    "\n",
    "    return Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_transition_test(data,batch_size=256):\n",
    "    df = pd.read_parquet(data)\n",
    "    s_col = [x for x in df if x[:2]=='s:']\n",
    "    a_col = [x for x in df if x[:2]=='a:']\n",
    "    r_col = [x for x in df if x[:2]=='r:']\n",
    "    dict = {}\n",
    "    dict['traj'] = {}\n",
    "\n",
    "    s = []\n",
    "    a = []\n",
    "    r = []\n",
    "\n",
    "    for traj in tqdm(df.traj.unique()):\n",
    "        df_traj = df[df['traj'] == traj]\n",
    "        dict['traj'][traj] = {'s':[],'a':[],'r':[]}\n",
    "        dict['traj'][traj]['s'] = df_traj[s_col].values.tolist()\n",
    "        dict['traj'][traj]['a'] = df_traj[a_col].values.tolist()\n",
    "        dict['traj'][traj]['r'] = df_traj[r_col].values.tolist()\n",
    "\n",
    "        step_len = len(df_traj) - rolling_size + 1\n",
    "        for step in range(step_len):\n",
    "            a.append(dict['traj'][traj]['s'][step])\n",
    "            a.append(dict['traj'][traj]['a'][step])\n",
    "            r.append(dict['traj'][traj]['r'][step])\n",
    "    \n",
    "    s = torch.FloatTensor(np.float32(s))\n",
    "    a = torch.LongTensor(np.int64(a))\n",
    "    r = torch.FloatTensor(np.float32(r))\n",
    "\n",
    "    Dataset = TensorDataset(s,a,r)\n",
    "    rt = DataLoader(Dataset,batch_size,shuffle=False)\n",
    "    return rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(Qnetwork, self).__init__()\n",
    "        self.layers = nn.ModuleList()  # 레이어를 담을 리스트 초기화\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "\n",
    "        # 입력 레이어\n",
    "        self.layers.append(nn.Linear(input_size, self.hidden_sizes[0]))\n",
    "\n",
    "        # 숨겨진 레이어들\n",
    "        for i in range(1, len(self.hidden_sizes)):\n",
    "            self.layers.append(nn.Linear(self.hidden_sizes[i - 1], self.hidden_sizes[i]))\n",
    "\n",
    "        # 출력 레이어\n",
    "        self.layers.append(nn.Linear(self.hidden_sizes[-1], output_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 숨겨진 레이어들을 순차적으로 적용\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = F.relu(layer(x))  # 활성화 함수로 ReLU 사용\n",
    "        # 출력 레이어 적용 (활성화 함수 없음)\n",
    "        x = self.layers[-1](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(batch_size,lr,lr_decay,lr_step,loss_type,gamma,alpha,epochs,state_dim,hidden_size,num_actions,update_freq,GCO,AESEVER):\n",
    "    network = Qnetwork(state_dim,hidden_size,num_actions)\n",
    "    target_network = Qnetwork(state_dim,hidden_size,num_actions)\n",
    "    gamma = 1.0\n",
    "    patience = 20\n",
    "    counters = 0\n",
    "    best_loss = 1e6\n",
    "\n",
    "    optimizer = optim.Adam(network.parameters(), lr=lr)\n",
    "    scheduler = ExponentialLR(optimizer, gamma=lr_decay)\n",
    "\n",
    "    train_data = make_transition(df,alpha,GCO,AESEVER)\n",
    "\n",
    "    train_loader = DataLoader(train_data,batch_size=batch_size,shuffle=True)\n",
    "    val_loader = DataLoader(train_data,batch_size=256,shuffle=False)\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss = 0\n",
    "        update_counter = 0\n",
    "        for s,a,r,s2,t in train_loader:\n",
    "            s = s.to(device)\n",
    "            a = a.to(device)\n",
    "            r = r.to(device)\n",
    "            s2 = s2.to(device)\n",
    "            t = t.to(device)\n",
    "\n",
    "            q = network(s)\n",
    "            q_pred = q.gather(1, a).squeeze()\n",
    "\n",
    "            q2 = target_network(s2).detach()\n",
    "            q2_net = network(s2).detach()\n",
    "\n",
    "            q2_max = q2.gather(1, torch.max(q2_net,dim=1)[1].unsqueeze(1)).squeeze(1).detach()\n",
    "\n",
    "            bellman_target = torch.clamp(r, max=0.0, min=-1.0) + gamma * torch.clamp(q2_max.detach(), max=0.0, min=-1.0)*(1-t)\n",
    "\n",
    "            if loss_type == \"l1\":loss = F.l1_loss(q_pred, bellman_target)\n",
    "            elif loss_type == \"smooth_l1\":loss = F.smooth_l1_loss(q_pred, bellman_target)\n",
    "            elif loss_type == \"mse\":loss = F.mse_loss(q_pred, bellman_target)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "\n",
    "            update_counter += 1\n",
    "            if update_counter == update_freq:\n",
    "                target_network.load_state_dict(network.state_dict())\n",
    "                update_counter = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            for s,a,r,s2,t in val_loader:\n",
    "                s = s.to(device)\n",
    "                a = a.to(device)\n",
    "                r = r.to(device)\n",
    "                s2 = s2.to(device)\n",
    "                t = t.to(device)\n",
    "\n",
    "                q = network(s)\n",
    "                q2 = target_network(s2).detach()\n",
    "                q_pred = q.gather(1, a).squeeze()\n",
    "\n",
    "                q2_net = network(s2).detach()\n",
    "                q2_max = q2.gather(1, torch.max(q2_net,dim=1)[1].unsqueeze(1)).squeeze()\n",
    "\n",
    "                bellman_target = torch.clamp(r, max=0.0, min=-1.0) + gamma * torch.clamp(q2_max.detach(), max=0.0, min=-1.0)*(1-t)\n",
    "\n",
    "                if loss_type == \"l1\":loss = F.l1_loss(q_pred, bellman_target)\n",
    "                elif loss_type == \"smooth_l1\":loss = F.smooth_l1_loss(q_pred, bellman_target)\n",
    "                elif loss_type == \"mse\":loss = F.mse_loss(q_pred, bellman_target)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "            q_value = []\n",
    "            reward  = []        \n",
    "            \n",
    "            for s,a,r in val_transition:\n",
    "                q = network(s.to(device))\n",
    "                q_value.append(q.detach().cpu().numpy())\n",
    "                reward.append(r.detach().cpu().numpy())\n",
    "\n",
    "            q_value = np.concatenate(q_value,axis=0)\n",
    "            q_max = q_value.max(axis=1)\n",
    "            auroc = roc_auc_score(reward,q_max)\n",
    "\n",
    "        wandb.log({\"Iter:\": epoch, \"train:\":train_loss, \"val:\":val_loss,\"counters\":counters,\"AUROC\":auroc})\n",
    "        \n",
    "        if (epoch%lr_step ==0):\n",
    "            scheduler.step()\n",
    "            continue\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            counters = 0\n",
    "        else :\n",
    "            counters += 1\n",
    "            if (counters > patience)&(epoch>=99):\n",
    "                break\n",
    "\n",
    "    return auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\",[16,32,64,128,256])\n",
    "    \n",
    "    lr = trial.suggest_categorical(\"learning_rate\",[1e-6,5e-6,1e-5,5e-5,1e-4,5e-4, 1e-3, 5e-3, 1e-2])\n",
    "    lr_decay = trial.suggest_categorical(\"lr_decay\",[0.75,0.8,0.85,0.9,0.95,1])\n",
    "    lr_step = trial.suggest_categorical(\"lr_step\",[2,5,10,20,30,50,100,200,250,500,1000])\n",
    "    \n",
    "    loss = trial.suggest_categorical(\"loss\",['smooth_l1','mse'])\n",
    "\n",
    "    update_freq = trial.suggest_categorical(\"update_freq\",[2,4,8,16,32])\n",
    "    hidden_size = trial.suggest_categorical(\"hidden_size\",[[32],[64],[32,32],[32,64],[64,32],[64,64]])\n",
    "    gamma = trial.suggest_categorical(\"gamma\",[0.8,0.85,0.9,0.95,0.97,0.98,0.99,0.999])\n",
    "    alpha = trial.suggest_categorical(\"alpha\",[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0])\n",
    "\n",
    "    GCO = trial.suggest_categorical(\"GCO\",[2,3,4,5])\n",
    "    AESEVER = trial.suggest_categorical(\"AESEVER\",[1,2,3])\n",
    "    \n",
    "    epochs = 100000\n",
    "\n",
    "    state_dim = len([x for x in df if x[:2]=='s:'])\n",
    "    num_actions = len(df['a:action'].unique())\n",
    "\n",
    "    wandb.init(\n",
    "        entity='dahs-hb',project='stru_ae_exp', name=f'trial-{trial.number}', reinit=True,\n",
    "        config={\n",
    "        \"batch_size\":batch_size,\n",
    "        \"learning_rate\":lr,\n",
    "        \"lr_decay\":lr_decay,\n",
    "        \"lr_step\":lr_step,\n",
    "        \"loss\":loss,\n",
    "        \"gamma\":gamma,\n",
    "        \"alpha\":alpha,\n",
    "        \"GCO\":GCO,\n",
    "        \"AESEVER\":AESEVER,\n",
    "        \"hidden_size\":hidden_size\n",
    "    })\n",
    "\n",
    "    auroc = train(batch_size,lr,lr_decay,lr_step,loss,gamma,alpha,epochs,state_dim,hidden_size,num_actions,update_freq,GCO,AESEVER)\n",
    "\n",
    "    return auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_params = study.best_params\n",
    "best_loss = study.best_value\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Validation Loss:\", best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
